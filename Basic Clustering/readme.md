# MNIST Embeddings & Clustering

Welcome! ğŸ˜Š This project explores the classic **MNIST** dataset (digits 0-9) and applies various **dimensionality reduction** techniques to the raw image data. After reducing dimensions, we cluster the data using different clustering algorithms. Letâ€™s dive in! ğŸš€

## âœ¨ Whatâ€™s Inside?

This project walks through:

- Loading and preprocessing the **MNIST dataset** 0ï¸âƒ£1ï¸âƒ£2ï¸âƒ£...9ï¸âƒ£
- Applying **dimensionality reduction** techniques:
  - **UMAP** ğŸ—ºï¸
  - **PCA** ğŸ“‰
  - **t-SNE** ğŸ”
- Clustering the reduced data using:
  - **DBSCAN** ğŸ“Œ
  - **HDBSCAN** ğŸ“
  - **K-Means** ğŸ¯

## ğŸ›  Tools Used

This project was built using **Google Colab** and the following libraries:

- **Matplotlib** - for visualizing results ğŸ“Š
- **NumPy** - for numerical computations ğŸ”¢
- **Scikit-learn** - for PCA, t-SNE, and clustering algorithms ğŸ—ï¸
- **UMAP** - for dimensionality reduction ğŸš€

## ğŸ“‚ How to Use

1. Open the notebook in **Google Colab**
2. Run the cells step by step to:
   - Load the MNIST dataset
   - Preprocess the data
   - Reduce dimensions
   - Apply clustering algorithms
3. Visualize and analyze the results ğŸ¨

## ğŸ¯ Goals

- Understand how dimensionality reduction techniques transform MNIST data
- Compare different dimensionality reduction methods
- Evaluate how clustering performs on reduced data

## ğŸ“ Notes

- Experiment with different numbers of PCA components or t-SNE perplexity values.
- UMAP often preserves local structures better than PCA/t-SNE.
- The clustering results depend on the choice of dimensionality reduction technique.
